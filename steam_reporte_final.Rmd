---
title: "Sistemas de Recomendación Implícita para videojuegos de plataforma Steam"
author: 
- Carlos Bautista
- Mario Heredia
- Miguel Reyes
output:
  html_document: default
---


# Examen final Métodos Analíticos. 

### Maestría en Ciencia de Datos ITAM {.tabset .tabset-fade .tabset-pills}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introducción

<<<<<<< Updated upstream
Los sistemas de recomendación funcionan como filtros clasifican la información que recibirá el usuario en una plataforma. El objetivo es mejorar la experiencia del usuario  a través de sugerencias personalizadas basadas en la retroalimentación.


Los sistemas de recomendación se clasifican de la siguiente manera. 

 1. Basados en contenido: Tomando en cuenta algunos datos del historial del usuario intenta  predecir qué busca el usuario y que sugerencias similares puede  mostrar. 
 
 2. Filtrado colaborativo: Recomienda nuevos productos según las interacciones de los usuarios y/o las calificaciones de varios productos. La recomendación se basa en usuarios que han hecho valoraciones semejantes o bien, encontrando la similitud entre artículos dada por el gusto de los usuarios. El filtrado colaborativo se alimenta de dos tipos de datos
 
    * Retroalimentación explícita: Se obtiene de evaluaciones claras dadas por los usuarios de los productos que les han interesado. Por ejemplo, los datos de clasificación de estrellas recopilados de las clasificaciones de películas de los usuarios. dados por los usuarios (por ejemplo, Netflix mucho tiempo fue así: $1-5$ estrellas). 

    * Retroalimentación implícita: Se obtiene de la actividad de los usuarios. Por ejemplo, historial de navegación, click en la descripción de un producto, el modo de búsqueda e incluso las acciones del mouse.
    
La mayoría de la literatura se ocupa del filtrado colaborativo con retroalimentación explícita. Un problema de procesar los comentarios explícitos es  que la información no siempre está disponible. Los usuarios pueden ser renuentes a calificar productos o por las limitaciones del sistema que no pueden recopilar datos de comentarios explícitos. En un modelo de filtrado colaborativo con retroalimentación imolícita,una vez que el usuario aprueba que se recolecte información, no se necesitan datos adicionales del lado del cliente.

Este trabajo desarrolla un modelo de filtrado colaborativo con retroalimentación implícita, está inspirado en el artículo de [Collaborative FIltering for Implicit Feedback Datasets](http://yifanhu.net/PUB/cf.pdf) en el que desarrollan un algoritmo de sistema de recomendación de programas de televisión para el usuario final.

El objetivo de este trabajo es realizar recomendaciones sobrevideojuegos, de acuerdo con su experiencia en la plataforma.


=======
>>>>>>> Stashed changes


# Base de datos

Los datos utilizados se obtuvieron de la base *Condensing Steam: Distilling the Diversity of Gamer Behavior*, que agrupa información histórica de 108.7 millones de usuarios recolectados en 2014 de la plataforma de videojuegos Steam, con 716 millones de juegos y hasta 1.1 millones de años en horas jugadas.

La base original está compuesta de 11 tablas de datos que contienen información diversa sobre los usuarios y sus atributos (id, juegos jugados, horas jugadas, información geográfica, información sobre sus "amigos", entre otros.), así como de los juegos y sus características (género, desarrollador, editor, etc.). Tiene un peso de 17.5GB comprimida, y 160GB al descomprimirse, y está en formato *.sql*. Para utilizarla, fue necesario restaurarla utilizando el sistema manejador de bases de datos *MariaDB*, el cual opera basado en *MySQL*.

Para el presente proyecto, se utilizó un subconjunto de *Condensing Steam* tomando de manera aleatoria 800 mil usuarios contenidos en la base. Se utilizan las tablas `Games_1` y `Games_2`, que contienen información sobre el id del jugador, id del juego o app, y el número de minutos jugados.

El diccionario que contiene la relación entre el id del videojuego y su nombre fue obtenida de https://github.com/dgibbs64/SteamCMD-AppID-List, y completada manualmente con ayuda de la herramienta web https://steamdb.info/.

Se identificó que existen algunos videojuegos con el mismo nombre, pero con diferente id, por lo cual se reindexó dicho catálogo, utilizando nombres de videojuegos únicos, y sumando el número de minutos de todos los jugadores, en caso de que tuvieran tiempo de juego en un app que tuviera dos ids.

El conjunto de datos resultante está compuesto de 7.2 millones de observaciones y 3 variables que son las que se utilizarán para construir el sistema de recomendación implícito:

 - `steamid`: el identificador del usuario de la plataforma
 - `app_name`: nombre del videojuego
 - `playtime_forever`: minutos totales que el usuario ha utilizado el videojuego.
 
Exploramos algunos datos de la tabla:

```{r}
cat_def <- read_rds('cache/cat_apps_def.rds')
cat_limpio <- read_rds('cache/cat_apps_limpio.rds')
dta_clean <- read_rds('cache/data_clean.rds')
head(dta_clean)
```

Del total de los usuarios recolectados, se eliminaron aquellos que estaban registrados en la plataforma y tenían al menos algún videojuego registrado pero sin haberlo jugado. En ese sentido, se tienen 732,759 usuarios diferentes que interactúan con 4,133 videojuegos.

```{r}
dim(dta_clean)
length(unique(dta_clean$steamid))
length(unique(dta_clean$app_name))
```

Respecto al número de minutos jugadas (playtime_forever), el resumen estadístico puede observarse a continuación:

```{r}
summary(dta_clean$playtime_forever)
```

## Split en entrenamiento y validación

Los datos se dividen en un conjunto de entrenamiento que nos servirá para construir el modelo y otro de validación con el que evaluaremos las recomendaciones sugeridas.



El set de validación se construye tomando los registros que pertenecen a la intersección de ambos conjuntos definidos anteriormente. Al ser la intersección, el porcentaje de la base conservado es aprox $ .5 *.5 = .25 = 25\% $.

El set de entrenamiento, entonces, se compone por todos los registros que NO pertenecen al set de validación.

Para ello, se extraen de manera aleatoria 50% de los usuarios de la plataforma (`steamid`), y después se extraen de manera aleatoria el 50% de los videojuegos (`app_name`). El set de validación se construye tomando los registros que pertenecen a la intersección de ambos conjuntos definidos anteriormente. Al ser la intersección, el porcentaje de la base conservado es aprox $ .5 *.5 = .25 = 25\% $, equivalente a 1.78 millones de observaciones. El set de entrenamiento, entonces, se compone por todos los registros restantes que no pertenecen al set de validación y equivalen a 5.42 millones de observaciones.

```{r}
dta_train <- read_rds('cache/dta_train.rds')
dta_validation <- read_rds('cache/dta_validation.rds')
dim(dta_train)
dim(dta_validation)
```

Despúes de la separación, el conjunto de entrenamiento contiene 652,117 usuarios distintos y 4,115 videojuegos, mientras que el de validación tiene 270,827 usuarios y 2,038 videojuegos.

```{r}
length(unique(dta_train$steamid))
length(unique(dta_train$app_name))
length(unique(dta_validation$steamid))
length(unique(dta_validation$app_name))
```



# Metodología

Sistema de recomendación busca resolver el problema de "predecir la respuesta de personas a estímulos a los que no han sido expuestos, basados en respuesta a otros estímulos de esta y quizá otras personas similares". 

El más común es el explícito, donde el usuario otorga una calificación al producto (típicamente en una escala del 1 a 5 estrellas), para lo cual se cuentan con modelos de recomendación y métricas de evaluación (RMSE) bien definidas a partir de dichas calificaciones explícitas.

Los sistemas de recomendación implícitos se refieren a contextos donde no se tiene una calificación/evaluación del producto explícitamente definida por el usuario, pero se tienen variables de acciones del usuario que reflejan la preferencia o popularidad del producto y que, en muchos casos, resultan más informativos que la calificación directa otorgoda por el usuario.

Nuestro sistema de recomendación se construye utilizando las horas jugadas por un usuario para cada videojuego.

## Modelo 

Para este trabajo consideramos el índice $u,v$ para distinguir usuarios; los artículos están determinados por los subíndices $i,j$. De tal forma que podemos relacionar a los usuarios y los artículos mediante la relación $r_{u,i}$.  Esta relación representa la frecuencia de acciones sobre un artículo, por ejemplo, el número de compras en un sitio web, el número de veces que oprimimos la tecla "favoritos", clics que damos a un producto en especial o el tiempo para ver / escuchar video / audio. Es decir, es una medida implícita para el usuario $u$ y el artículo $i$. $r_{u,i}$lo entendemos, en el contexto de recomendación implícita, como las observaciones que se tienen. Hay que notar que en la recomendación explícita estos valores serían llamados los "ratings" otorgados a los artículos. Importante reiterar que aquí le llamamos observaciones.


Para poner en contexto, $r_{u,i}$ puede indicar el número de ocasiones que el individuo $u$ adquiere el artículo $i$. O bien el tiempo que $u$ navega en el sitio web de $i$.En nuestro ejercicio, $r_{u,i}$ indica el tiempo que un individuo dedica a jugar un videojuego en específico.

Para nuestro modelo, consideramos la variable binaria $p_{u,i}$ que nos indica la preferencia del usuario $u$ por un artículo $i$. 
$$
P_{u,i} =\left\{ \begin{array}{rcl}
 1\;\;si\;\;\;\; r_{u,i}\;>\; 0 \\ 0\;\;si\;\;\;\; r_{u,i}\;=\;0 
\end{array}\right.
$$
$p_{u,i}\;=\;1$ nos indica que el usuario $u$ consume el artículo $i$, donde $r_{u,i} > 0$. Es decir, las observaciones entre el usuario y el artículo son positivas. 

$p_{u,i}\;=\;0$ nos indica que el usuario $u$ no consume el bien $i$,donde $r_{u,i} = 0$. Es decir, no hay observaciones entre el usuario y el artículo. 

En este sentido, si $p_{u,i}\;=\;0$, nos haría creer que el individuo $u$ no tiene preferencia por ese bien. Si sólo utilizamos $p_{u,i}$ se pensará que  el usuario actúa con un comportamiento binario. Si compra un producto, es porque le gusta el producto; de lo contrario, significa que al usuario no le gusta el producto. Hay que tener cuidado con esta  apreciación porque la realidad no es tan simple, la compra de un artículo por parte de un usuario no significa necesariamente que le guste al usuario, éste puede ser comprado como un regalo.


Para corregir este sesgo binario, tenemos que considerar que nuestras creencias sobre las preferencias están asociadas con niveles de confianza muy variables, no son binarias. En primer lugar, por la naturaleza de los datos, cuando $p_{u,i}\;=\;0$ se asocia con una confianza baja, pero no  tomar ninguna acción positiva sobre un elemento puede deberse a muchas otras razones más allá de que no le guste. Aquí hay que tener en cuenta que el usuario puede desconocer la existencia de algún bien, en nuestro caso, de un videojuego. Incluso puede no consumirlo por el precio o disponibilidad.

Los individuos tenemos distintos niveles de confianza entre los bienes que se consumen, incluso entre los elementos que son preferidos por el usuario. En general si $r_{u,i}$ crece, es un indicador que el usuario tiene mayor prefrencia por el artículo.

Para saber qué tanto valor debemos darle a la preferencia, necesitamos modelar un nivel de confianza para mostrar que los usuarios prefieren un determinado producto. La confianza la medimos de la siguiente forma: 
$$c_{ui} = 1+ \alpha r_{ui},$$
Así obtenemos una confianza mínima en $p_{u,i}$

$C_{u,i}$mide la confianza en la observación $p_{u,i}$.

$\alpha$ es un parámetro constante de la tasa de incremento de la variable. Es un coeficiente de confianza que aumenta mientras observamos más evidencia del sesgo positivo.
 
Asumimos que las preferencias son el producto punto de $p_{u,i}\;=\;x_u^Ty_i$. Estos vectores corresponden al usuario $u$ y al artículo $i$
 
Estos dos vectores son referentes a los usuarios y los productos, lo que deseamos es compararlos directamente. Esta técnica es similar a la factorización de matrices que se realiza en recomendación explícita, pero con dos distinciones importantes: a) Necesitamos tomar en cuenta la variedad de los niveles de confianza; b) La optimización debe considerar todos los posibles pares de $u,i$, no solamente los observados. De acuerdo con esto, la función de pérdida que debe ser minimizada se ve de la siguiente forma: 
$$ \min_{x*,y*}\sum_{u,i} C_{u,i}(p_{u,i}-x_u^Ty_i)^2 \;+\; \lambda(\sum_{u}\|x_u\|^2\;+\;\sum_{i}\|y_u\|^2)$$
Donde $\lambda(\sum_{u}\|x_u\|^2\;+\;\sum_{i}\|y_u\|^2)$ es un parámetro de regularización y se hace una normalización para evitar el sobreajuste. $\lambda$ es uno de los parámetros que hay que ajustar.

La función de pérdida que queremos minimizar contiene $m.n$ términos, donde $m$ es el número de usuarios y $n$ es el número de artículos. Esto implica que tenemos un número grande de términos que no podemos optimizar directamente con técnicas de optimización comunes como descenso en gradiente estocástico. Para optimizar utilizamos el algoritmo de Mínimos Cuadrados Alternados (ALS)

## Alternating Least Squares (ALS)

El sistema de recomendación implícita, se crea por medio del algoritmo ALS, con base en *Collaborative Filtering for Implicit Feedback Datasets* (Hu, Koren and Volinsky 2008). Es un algoritmo de recomendación capaz de identificar artículos similares y hacer recomendaciones para los usuarios.

<<<<<<< Updated upstream
La implementación del algoritmo está hecha en [spark](https://www.rdocumentation.org/packages/sparklyr/versions/1.1.0/topics/ml_als)
=======
Para su implementación, se utiliza la función `spark.als()` del paquete `SparkR`, utilizando el argumento `implicit = TRUE`, para asegurarse de utilizar el algoritmo adecuado para calificaciones implícitas.
>>>>>>> Stashed changes

## Evaluación

La evaluación para modelos implícitos no es tan simple como en el caso explícito, pues no estamos modelando
directamente los valores observados $r_{u,i}$.  

Lo recomendable para cada usuario $i$, es generar un rango de los artículos de mayor a menor valor de $\hat{p}_{ui} = u_iv_j^t$ (juegos), y calcular

$$
\overline{rank} = \frac{\sum_{u,i} r_{ui}^t\;rank_{ui}}{\sum_{u,i}\;r_{ui}^t}
$$

que se refiere al rango de la matriz de factores latentes. Valores bajos de $\overline{rank}$ son más deseables, pues ellos indican que el orden de los juegos más utilizados están más cerca de la parte superior de la lista. 

Podemos decir que $\overline{rank} \;=\;0$ para el mejor juego y $\overline{rank} \;=\;1$ para el peor. Los valores más bajos son obtenidos si los usuarios interactúan más con artículos que están encima en el ranking.

***NOTA. cambiar lado derecho de la ecuación a percentil u,i en lugar de rank u,i y explicar.***

Es importante mencionar que para construir el sistema de recomendación, la variable `appid` se convirtió de minutos a horas de juego, debido que al reducir la variación en la escala se lograron mejores resultados en la ***predicción y evaluación***.



Consideraciones sobre evaluación


# Resultados

SISTEMA DE RECOMENDACIÓN

Se utiliza la función `SparkR::predict()` para obtener las predicciones del nivel de gusto en el conjunto de prueba.

Adicional a esto, para cada usuario se toma una muestra aleatoria de $n = 40$ del conjunto de los 250 juegos o apps más populares, según el número total de horas de juego, del conjunto de entrenamiento.

De esta manera, para cada usuario se calculan las predicciones del nivel de preferencia de los 40 juegos aleatorios que le fueron asignados, además de los juegos para los cuales se tiene información sobre el tiempo de juego.

Como se explica en las notas y en el paper, se calcula una métrica de evaluación llamada `rank`, la cual consiste en rankear los niveles de preferencia de todos los juegos, por usuario. Posteriormente, se calcula el percentil de cada observación, por usuario, de manera que los juegos con mayor preferencia predicha tienen un percentil más bajo, y vice versa. De esta manera, mientras mejor sea la predicción, menor será el valor de `rank`

Después, únicamente para los juegos que pertenecen al conjunto de prueba, se multiplica el número de horas jugadas por el percentil al cual corresponden. Y al final se divide entre el número total de horas jugadas.
La idea intuitiva, es que, mientras más acierte el modelo en rankear correctamente los niveles de preferencia, más veces se multiplicarán por valores bajos de percentiles, obteniendo así mejores valores de "rank".

Se conserva el modelo con mejor valor para la métrica de ajuste.

Se corrieron XX configuraciones de modelos (y tabla)

El mejor modelo: 

- La mejor configuración fue lamda 150, rank 80, y alpha 1.

- Lamda es el que más afecta los resultados. el rank si afecta pero no mucho. El valor de alpha fue el mejor 1 (default).


- Gráfica rank vs count (cero donde mejor lo hace), por lo tanto esperaríamos mayor densidad en valores cercanos a cero.

- Para un usuario particular (id = 15), el que más jugó le dio una recomendación alta. Otros ejemplos donde usuario jugó poquito y le dio

VALOR DE 0.17 y explicación

RECOMENDACIONES EXITOSAS DE ARTÍCULOS ESPECÍFICOS (tablas)

ejemplo de FALLOS (tablas)


# Conclusiones

VENTAJA DE SISTEMA DE RECOMENDACIÓN IMPLICITO. puede ser más informativo


CONCLUSIONES SOBRE RESULTADOS

notas. 



EFECTOS OBSERVADOS DE PARÁMETROS

DIFERENCIAS ESPECÍFICAS SOBRE RECOMENDACIÓN DE VIDEOJUEGOS Y PELICULAS (CONTEXTO)
Ver paper.
Diferentes inherentes desde la recolección de los datos en Steam vs otras plataformas. QUE ES STEAM, plataforma que instalas y para jugar necesitas iniciar sesión, te monitorea toda tu actividad, etc.


FUTURAS LINEAS DE INVESTIGACIÓN (RETOS PARA EL EQUIPO)
En general el tamaño de datos, limitaciones de cómputo (más usuarios, más juegos, etc.)





**PENDIENTES**

CBP: INCORPORAR NOTAS DE MARIO Y AFINAR ESTILO Y REDACCIÓN

MRR: INTRODUCCIÓN Y COMENTARIOS A SECCIÓN DE MODELO

MHT: RESULTADOS

TODOS: IDEAS PARA CONCLUSIONES
